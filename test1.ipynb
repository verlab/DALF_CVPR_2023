{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 1., 1.],\n",
      "          [1., 1., 1.]]]])\n",
      "tensor([[[[False,  True,  True],\n",
      "          [ True,  True,  True]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# 根据热图（Heatmap）采样关键点（keypoints）TODO\n",
    "class KeypointSampler(nn.Module):\n",
    "  '''\n",
    "  Sample keypoints according to a Heatmap\n",
    "  Input\n",
    "    x: [B, 1, H, W] heatmap\n",
    "\n",
    "  Returns\n",
    "    [list]:\n",
    "      kps: [N, 2] - keypoint positions\n",
    "      log_probs: [N] - logprobs for each kp\n",
    "  '''  \n",
    "  def __init__(self, window_size = 8): \n",
    "    super().__init__()\n",
    "    self.window_size = window_size\n",
    "\n",
    "  # 将输入的热图张量进行划分，划分成一个个的窗口。\n",
    "  def gridify(self, x):\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.unfold(2, self.window_size, self.window_size)                              \\\n",
    "          .unfold(3, self.window_size, self.window_size)                             \\\n",
    "          .reshape(B, C, H//self.window_size, W//self.window_size, self.window_size**2)\n",
    "\n",
    "    return x\n",
    "\n",
    "  def sample(self, grid):\n",
    "    '''\n",
    "    Sample keypoints given a grid where each cell has logits stacked in last dimension\n",
    "    Input\n",
    "      grid: [B, C, H//w, W//w, w*w]\n",
    "\n",
    "    Returns\n",
    "      log_probs: [B, C, H//w, W//w ] - logprobs of selected samples\n",
    "      choices: [B, C, H//w, W//w] indices of choices\n",
    "      accept_mask: [B, C, H//w, W//w] mask of accepted keypoints\n",
    "\n",
    "    '''\n",
    "    chooser = torch.distributions.Categorical(logits = grid)\n",
    "    choices = chooser.sample()\n",
    "    selected_choices = torch.gather(grid, -1, choices.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    flipper = torch.distributions.Bernoulli(logits = selected_choices)\n",
    "    accepted_choices = flipper.sample()\n",
    "\n",
    "    #Sum log-probabilities is equivalent to multiplying the probabilities\n",
    "    log_probs = chooser.log_prob(choices) + flipper.log_prob(accepted_choices)\n",
    "    print(accepted_choices)\n",
    "    accept_mask = accepted_choices.gt(0)\n",
    "    print(accept_mask)\n",
    "    return log_probs.squeeze(1), choices, accept_mask.squeeze(1)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    B, C, H, W = x.shape\n",
    "    keypoint_cells = self.gridify(x)\n",
    "    idx_cells = self.gridify( torch.dstack(torch.meshgrid(torch.arange(x.shape[-2], dtype=torch.float32),\n",
    "                                                          torch.arange(x.shape[-1], dtype=torch.float32),\n",
    "                                                          #indexing='ij'))     \\\n",
    "                                                                        ))     \\\n",
    "                                                         .permute(2,0,1).unsqueeze(0) \n",
    "                                                         .expand(B,-1,-1,-1) ).to(x.device)\n",
    "                                                         \n",
    "\n",
    "    log_probs, idx, mask = self.sample(keypoint_cells)\n",
    "    \n",
    "\n",
    "    keypoints = torch.gather(idx_cells, -1, idx.repeat(1,2,1,1).unsqueeze(-1)).squeeze(-1).permute(0,2,3,1)\n",
    "    \n",
    "    xy_probs = [  {'xy':keypoints[b][mask[b]].flip(-1), 'logprobs':log_probs[b][mask[b]]}\n",
    "                  for b in range(B) ]\n",
    "\n",
    "    return xy_probs\n",
    "\n",
    "key1 = KeypointSampler(2)\n",
    "tensor = torch.rand(1, 1, 4, 6)\n",
    "xy_p = key1(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6])\n",
      "tensor([[-1.8381, -1.4853, -1.9711, -2.2752, -1.7852, -1.5867],\n",
      "        [-1.7578, -1.7432, -1.8685, -1.9225, -1.6718, -1.8072],\n",
      "        [-1.6294, -2.3135, -1.6149, -1.6106, -1.7604, -2.0069],\n",
      "        [-1.6025, -2.2470, -1.4916, -1.8455, -1.7750, -1.9629],\n",
      "        [-1.7107, -1.9723, -1.7986, -1.7264, -1.6720, -1.9053],\n",
      "        [-1.7509, -2.1092, -2.1430, -1.5009, -1.5810, -1.8385]])\n",
      "tensor([1, 4, 3, 2, 4, 3])\n",
      "tensor([-1.4853, -1.6718, -1.6106, -1.4916, -1.6720, -1.5009])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "x = torch.rand(6,3)\n",
    "y = torch.rand(6,3)\n",
    "T = 1.\n",
    "\n",
    "\n",
    "Dmat = 2. - torch.cdist(x.unsqueeze(0), y.unsqueeze(0)).squeeze(0)\n",
    "print(Dmat.shape)\n",
    "logprob_rows = F.log_softmax(Dmat * T, dim=1)\n",
    "print(logprob_rows)\n",
    "logprob_cols = F.log_softmax(Dmat.t() * T, dim=1)\n",
    "choice_rows = torch.argmax(logprob_rows, dim=1)\n",
    "print(choice_rows)\n",
    "choice_cols = torch.argmax(logprob_cols, dim=1)\n",
    "\n",
    "seq = torch.arange(choice_cols.shape[0], dtype = choice_cols.dtype, device = choice_cols.device)\n",
    "mutual = choice_rows[choice_cols] == seq\n",
    "\n",
    "logprob_rows = torch.gather(logprob_rows, -1, choice_rows.unsqueeze(-1)).squeeze(-1)\n",
    "print(logprob_rows)\n",
    "logprob_cols = torch.gather(logprob_cols, -1, choice_cols.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "log_probs = logprob_rows[choice_cols[mutual]] + logprob_cols[seq[mutual]]\n",
    "\n",
    "dmatches = torch.cat((choice_cols[mutual].unsqueeze(-1), seq[mutual].unsqueeze(-1)), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4079, 1.7607, 1.2749, 0.9709, 1.4608, 1.6594],\n",
      "        [1.3955, 1.4101, 1.2849, 1.2308, 1.4815, 1.3461],\n",
      "        [1.3891, 0.7050, 1.4036, 1.4079, 1.2581, 1.0116],\n",
      "        [1.5784, 0.9338, 1.6892, 1.3354, 1.4058, 1.2179],\n",
      "        [1.3964, 1.1349, 1.3086, 1.3808, 1.4352, 1.2019],\n",
      "        [1.4382, 1.0798, 1.0461, 1.6881, 1.6080, 1.3506]])\n",
      "tensor([-1.4853, -1.6718, -1.6106, -1.4916, -1.6720, -1.5009])\n",
      "tensor([[0, 1],\n",
      "        [3, 2],\n",
      "        [5, 3]])\n",
      "tensor([-2.7467, -2.9476, -2.9630])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(Dmat)\n",
    "print(logprob_rows)\n",
    "print(dmatches )\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=4, out_features=8, bias=True)\n"
     ]
    }
   ],
   "source": [
    "in_channels=2\n",
    "nparam = 4\n",
    "attn = nn.Sequential(\n",
    "                    nn.Linear(in_channels*2, in_channels*4),\n",
    "                    nn.BatchNorm1d(in_channels*4, affine = False),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(in_channels*4, in_channels*4),\n",
    "                    #nn.BatchNorm1d(in_channels*4, affine = False),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(in_channels*4, nparam*2),\n",
    "                    nn.Tanh(),\n",
    "                    )\n",
    "print(attn[0])\n",
    "#zero-out layer params for initial identity TPS transform\n",
    "for i in [-2, -5, -9]:\n",
    "    attn[i].weight.data.normal_(0., 1e-5) \n",
    "    attn[i].bias.data.zero_()#normal_(0., 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.071] global loadsave.cpp:248 findDecoder imread_('test.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 75\u001b[0m\n\u001b[1;32m     56\u001b[0m c_src \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m     57\u001b[0m     [\u001b[38;5;241m0.44\u001b[39m, \u001b[38;5;241m0.18\u001b[39m],\n\u001b[1;32m     58\u001b[0m     [\u001b[38;5;241m0.55\u001b[39m, \u001b[38;5;241m0.18\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     [\u001b[38;5;241m0.67\u001b[39m, \u001b[38;5;241m0.80\u001b[39m],\n\u001b[1;32m     63\u001b[0m ])\n\u001b[1;32m     65\u001b[0m c_dst \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m     66\u001b[0m     [\u001b[38;5;241m0.693\u001b[39m, \u001b[38;5;241m0.466\u001b[39m],\n\u001b[1;32m     67\u001b[0m     [\u001b[38;5;241m0.808\u001b[39m, \u001b[38;5;241m0.466\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     [\u001b[38;5;241m0.954\u001b[39m, \u001b[38;5;241m0.966\u001b[39m],\n\u001b[1;32m     72\u001b[0m ])\n\u001b[0;32m---> 75\u001b[0m warped_front \u001b[38;5;241m=\u001b[39m \u001b[43mwarp_image_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_dst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m show_warped(img, warped1, c_src_front, c_dst_front)\n",
      "Cell \u001b[0;32mIn[1], line 49\u001b[0m, in \u001b[0;36mwarp_image_cv\u001b[0;34m(img, c_src, c_dst, dshape)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwarp_image_cv\u001b[39m(img, c_src, c_dst, dshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     48\u001b[0m     dshape \u001b[38;5;241m=\u001b[39m dshape \u001b[38;5;129;01mor\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 49\u001b[0m     theta \u001b[38;5;241m=\u001b[39m \u001b[43mtps\u001b[49m\u001b[38;5;241m.\u001b[39mtps_theta_from_points(c_src, c_dst, reduced\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m     grid \u001b[38;5;241m=\u001b[39m tps\u001b[38;5;241m.\u001b[39mtps_grid(theta, c_dst, dshape)\n\u001b[1;32m     51\u001b[0m     mapx, mapy \u001b[38;5;241m=\u001b[39m tps\u001b[38;5;241m.\u001b[39mtps_grid_to_remap(grid, img\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tps' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "class TPS:       \n",
    "    @staticmethod\n",
    "    def fit(c, lambd=0., reduced=False):       \n",
    "        n = c.shape[0]\n",
    "\n",
    "        U = TPS.u(TPS.d(c, c))\n",
    "        K = U + np.eye(n, dtype=np.float32)*lambd\n",
    "\n",
    "        P = np.ones((n, 3), dtype=np.float32)\n",
    "        P[:, 1:] = c[:, :2]\n",
    "        v = np.zeros(n+3, dtype=np.float32)\n",
    "        v[:n] = c[:, -1]\n",
    "\n",
    "        A = np.zeros((n+3, n+3), dtype=np.float32)\n",
    "        A[:n, :n] = K\n",
    "        A[:n, -3:] = P\n",
    "        A[-3:, :n] = P.T\n",
    "        theta = np.linalg.solve(A, v) # p has structure w,a\n",
    "        return theta[1:] if reduced else thete      \n",
    "\n",
    "    @staticmethod\n",
    "    def z(x, c, theta):\n",
    "        x = np.atleast_2d(x)\n",
    "        U = TPS.u(TPS.d(x, c))\n",
    "        w, a = theta[:-3], theta[-3:]\n",
    "        reduced = theta.shape[0] == c.shape[0] + 2\n",
    "        if reduced:\n",
    "            w = np.concatenate((-np.sum(w, keepdims=True), w))\n",
    "        b = np.dot(U, w)\n",
    "        return a[0] + a[1]*x[:, 0] + a[2]*x[:, 1] + b\n",
    "\n",
    "\n",
    "\n",
    "def show_warped(img, warped, c_src, c_dst):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16,8))\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    axs[0].imshow(img[...,::-1], origin='upper')\n",
    "    axs[0].scatter(c_src[:, 0]*img.shape[1], c_src[:, 1]*img.shape[0], marker='^', color='black')\n",
    "    axs[1].imshow(warped[...,::-1], origin='upper')\n",
    "    axs[1].scatter(c_dst[:, 0]*warped.shape[1], c_dst[:, 1]*warped.shape[0], marker='^', color='black')\n",
    "    plt.show()\n",
    "\n",
    "def warp_image_cv(img, c_src, c_dst, dshape=None):\n",
    "    dshape = dshape or img.shape\n",
    "    theta = tps.tps_theta_from_points(c_src, c_dst, reduced=True)\n",
    "    grid = tps.tps_grid(theta, c_dst, dshape)\n",
    "    mapx, mapy = tps.tps_grid_to_remap(grid, img.shape)\n",
    "    return cv2.remap(img, mapx, mapy, cv2.INTER_CUBIC)\n",
    "\n",
    "img = cv2.imread('test.jpg')\n",
    "\n",
    "c_src = np.array([\n",
    "    [0.44, 0.18],\n",
    "    [0.55, 0.18],\n",
    "    [0.33, 0.23],\n",
    "    [0.66, 0.23],\n",
    "    [0.32, 0.79],\n",
    "    [0.67, 0.80],\n",
    "])\n",
    "\n",
    "c_dst = np.array([\n",
    "    [0.693, 0.466],\n",
    "    [0.808, 0.466],\n",
    "    [0.572, 0.524],\n",
    "    [0.923, 0.524],\n",
    "    [0.545, 0.965],\n",
    "    [0.954, 0.966],\n",
    "])\n",
    "\n",
    "\n",
    "warped_front = warp_image_cv(img, c_src, c_dst, dshape=(512, 512))\n",
    "show_warped(img, warped1, c_src_front, c_dst_front)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "batchSize = 10\n",
    "gridSize = (32,32)\n",
    "\n",
    "ident = torch.tensor([[[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]], device = 'cpu').expand(batchSize, -1, -1)\n",
    "grid = F.affine_grid(ident, (batchSize, 1) + gridSize, align_corners= False)\n",
    "grid_y = grid[..., 0].view(batchSize , -1)\n",
    "grid_x = grid[..., 1].view(batchSize , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 3])\n",
      "torch.Size([10, 32, 32, 2])\n",
      "torch.Size([10, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(ident.shape)\n",
    "print(grid.shape)\n",
    "print(grid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 32, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3,2)+(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doppelgangers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
