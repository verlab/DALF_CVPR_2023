{"cells":[{"cell_type":"markdown","metadata":{"id":"XnBrT_c10di_"},"source":["## Clone DALF repo"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"CqCM5qBfz-7I"},"outputs":[],"source":["WORKING_DIR = '../../DALF_CVPR_2023'\n","import sys\n","sys.path.append(WORKING_DIR)"]},{"cell_type":"markdown","metadata":{"id":"Ythr9Qjg0jnv"},"source":["# Initialize DALF model"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"N_mGOXI086vP"},"outputs":[{"name":"stdout","output_type":"stream","text":["running DALF on cpu\n","[64, 64, 32, 1]\n","[64, 64, 32, 1]\n","backbone: 64 hardnet: 64\n","adding fusion layer...\n"]}],"source":["from modules.models.DALF import DALF_extractor as DALF\n","import torch\n","import cv2\n","\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device = torch.device('cpu')\n","dalf = DALF(dev = device)"]},{"cell_type":"markdown","metadata":{"id":"zqX09gKvbGOf"},"source":["# Video registration with DALF\n","Here, we open a .mp4 video, use the first frame as the template, and track the template along the video. Please use GPU for faster inference, otherwise it may take a while."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"n7yzlnD0bFLH"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 1/279 [01:24<6:32:50, 84.79s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 43\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img2 \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(in_frames):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m#Compute DALF features\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     kps2, descs2 \u001b[38;5;241m=\u001b[39m \u001b[43mdalf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectAndCompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m#Match using vanilla opencv matcher\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     matcher \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mBFMatcher(crossCheck \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m~/workspace/code/ex1/DALF_CVPR_2023/notebooks/../../DALF_CVPR_2023/modules/models/DALF.py:116\u001b[0m, in \u001b[0;36mDALF_extractor.detectAndCompute\u001b[0;34m(self, og_img, mask, top_k, return_map, threshold, MS)\u001b[0m\n\u001b[1;32m    113\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(og_img, \u001b[38;5;28;01mNone\u001b[39;00m, fx \u001b[38;5;241m=\u001b[39m scale, fy \u001b[38;5;241m=\u001b[39m scale, interpolation \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mINTER_AREA) \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1.\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m og_img\n\u001b[1;32m    114\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(img, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.\u001b[39m\n\u001b[0;32m--> 116\u001b[0m kpts, descs, fmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNMS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m score_map \u001b[38;5;241m=\u001b[39m fmap[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m#utils.plot_grid([kpts[0]['patches'][:16]])\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/doppelgangers/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/doppelgangers/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/workspace/code/ex1/DALF_CVPR_2023/notebooks/../../DALF_CVPR_2023/modules/models/DALF.py:441\u001b[0m, in \u001b[0;36mDEAL.forward\u001b[0;34m(self, x, NMS, threshold, return_tensors, top_k)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m#print('optimize tps? ', optimize_tps, self.mode)\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimize_tps:\n\u001b[0;32m--> 441\u001b[0m   patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtps_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkpts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B): \n\u001b[1;32m    443\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m optimize_tps:\n","File \u001b[0;32m~/anaconda3/envs/doppelgangers/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/doppelgangers/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/workspace/code/ex1/DALF_CVPR_2023/notebooks/../../DALF_CVPR_2023/modules/models/DALF.py:609\u001b[0m, in \u001b[0;36mThinPlateNet.forward\u001b[0;34m(self, x, in_imgs, keypts, Ho, Wo)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B):\n\u001b[1;32m    608\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m keypts[b][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keypts[b][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m:\n\u001b[0;32m--> 609\u001b[0m     polargrid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_polar_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     N, H, W, _ \u001b[38;5;241m=\u001b[39m polargrid\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    612\u001b[0m     kfactor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n","File \u001b[0;32m~/workspace/code/ex1/DALF_CVPR_2023/notebooks/../../DALF_CVPR_2023/modules/models/DALF.py:571\u001b[0m, in \u001b[0;36mThinPlateNet.get_polar_grid\u001b[0;34m(self, keypts, Hs, Ws, coords, gridSize, maxR)\u001b[0m\n\u001b[1;32m    566\u001b[0m t_s \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    567\u001b[0m     grid_x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    568\u001b[0m ) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi\n\u001b[1;32m    570\u001b[0m x_coord \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(keypts[:, \u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, grid_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m Ws \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[0;32m--> 571\u001b[0m y_coord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypts\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, grid_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m Hs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[1;32m    573\u001b[0m aspectRatio \u001b[38;5;241m=\u001b[39m Ws\u001b[38;5;241m/\u001b[39mHs\n\u001b[1;32m    575\u001b[0m x_s \u001b[38;5;241m=\u001b[39m r_s \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mcos(\n\u001b[1;32m    576\u001b[0m     t_s\n\u001b[1;32m    577\u001b[0m ) \u001b[38;5;241m+\u001b[39m x_coord \n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from modules.tps import RANSAC\n","from modules.tps import numpy as tps_np\n","from modules.tps import pytorch as tps_pth\n","\n","import torch.nn.functional as F\n","\n","import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def warp_image_cv(img, c_src, c_dst, dshape = None):\n","    img = torch.tensor(img).to(device).permute(2,0,1)[None, ...].float()\n","    dshape = dshape or img.shape\n","    theta = tps_np.tps_theta_from_points(c_src, c_dst, reduced=True, lambd=0.01)\n","    theta = torch.tensor(theta).to(device)[None, ...]\n","    grid = tps_pth.tps_grid(theta, torch.tensor(c_dst, device=device), dshape)\n","    #print(grid.shape, grid.dtype)\n","    img = F.grid_sample(img, grid, align_corners=False)\n","    return img[0].permute(1,2,0).cpu().numpy().astype(np.uint8)\n","\n","# Open the MP4 file\n","cap = cv2.VideoCapture(WORKING_DIR + '/assets/deform_bag.mp4') \n","\n","ret, img1 = cap.read()\n","kps1, descs1 = dalf.detectAndCompute(img1)\n","nframe = 0\n","\n","in_frames = []\n","out_frames = []\n","\n","# Loop through the frames\n","while cap.isOpened():\n","    # Read a frame\n","    ret, img = cap.read()\n","    if ret:\n","        in_frames.append(img)\n","    else:\n","        break\n","    \n","\n","for img2 in tqdm.tqdm(in_frames):\n","    #Compute DALF features\n","    kps2, descs2 = dalf.detectAndCompute(img2)\n","\n","    #Match using vanilla opencv matcher\n","    matcher = cv2.BFMatcher(crossCheck = True)\n","    matches = matcher.match(descs1, descs2)\n","\n","    src_pts = np.float32([kps1[m.queryIdx].pt for m in matches])\n","    tgt_pts = np.float32([kps2[m.trainIdx].pt for m in matches])\n","\n","    #Computes non-rigid RANSAC\n","    inliers = RANSAC.nr_RANSAC(src_pts, tgt_pts, device,  batch = 3_000, thr = 0.2)\n","    good_matches = [matches[i] for i in range(len(matches)) if inliers[i]]\n","\n","    h, w = img1.shape[:2]\n","\n","    c_src = np.float32([kps1[m.queryIdx].pt for m in good_matches]) / np.float32([w,h])\n","    c_dst = np.float32([kps2[m.trainIdx].pt for m in good_matches]) / np.float32([w,h])\n","\n","    #Warp deformed image (img2) into template\n","    warped = warp_image_cv(img2, c_dst, c_src)\n","\n","    result = np.hstack([cv2.resize(img1, (w // 4, h // 4)),\n","                        cv2.resize(img2, (w // 4, h // 4)),\n","                        cv2.resize(warped, (w // 4, h // 4))])\n","    out_frames.append(result)\n","\n","    #plt.imshow(result), plt.show()\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"x3fIqlNJ0EAI"},"source":["#Generate GIF\n","Finally, we generate a GIF with the tracking result and save it! This gif is used in the README of DALF's git repo ðŸ”¥"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XtiU1XIitSpW"},"outputs":[],"source":["#Generate GIF\n","\n","import cv2\n","import imageio\n","import numpy as np\n","\n","with imageio.get_writer(\"out.gif\", mode=\"I\") as writer:\n","    # Loop through the frames and write them to the GIF writer object\n","    for frame in tqdm.tqdm(out_frames):\n","        writer.append_data(frame[..., ::-1])\n","\n","from IPython.display import Image\n","Image(open('out.gif','rb').read())"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNasalGUQ/6d/pQRyryhi7a","provenance":[{"file_id":"1kD0aJ_v6sdtvLtW5H-xMERWrPGPwPMMY","timestamp":1682631763798}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
